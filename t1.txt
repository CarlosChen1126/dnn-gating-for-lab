ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): QuantizedConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): QuantizedConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (conv1): QuantizedConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): QuantizedConv2d(
        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): LambdaLayer()
    )
    (1): BasicBlock(
      (conv1): QuantizedConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (conv1): QuantizedConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): QuantizedConv2d(
        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): LambdaLayer()
    )
    (1): BasicBlock(
      (conv1): QuantizedConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (conv1): QuantizedConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QuantizedConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (quantize_w): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
        (quantize_a): TorchQuantize(
          (quantize): TorchRoundToBits()
        )
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): PactReLU()
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=64, out_features=10, bias=True)
  (relu): PactReLU()
)